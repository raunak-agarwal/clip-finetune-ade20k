{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U spacy\n",
    "# !pip install nltk\n",
    "# !python3 -m spacy download en_core_web_sm\n",
    "from pprint import pprint\n",
    "import string\n",
    "import numpy as np\n",
    "p=string.punctuation\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import jsonlines\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ade20k_train_captions.jsonl\t  train_captions      val_captions\r\n",
      "ade20k_validation_captions.jsonl  train_captions.zip  val_captions.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/ADE20K-pairs/captions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADE_train_00003661</td>\n",
       "      <td>In this picture I can see the inside view of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADE_train_00003722</td>\n",
       "      <td>This is a picture taken inside of a room in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADE_train_00013827</td>\n",
       "      <td>In this image we can see monitors, keyboards, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADE_train_00009835</td>\n",
       "      <td>There is a building at the bottom of this imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADE_train_00002932</td>\n",
       "      <td>At the bottom of the image there is a bed with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id                                            caption\n",
       "0  ADE_train_00003661  In this picture I can see the inside view of a...\n",
       "1  ADE_train_00003722  This is a picture taken inside of a room in th...\n",
       "2  ADE_train_00013827  In this image we can see monitors, keyboards, ...\n",
       "3  ADE_train_00009835  There is a building at the bottom of this imag...\n",
       "4  ADE_train_00002932  At the bottom of the image there is a bed with..."
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = \"../data/ADE20K-pairs/captions/ade20k_train_captions.jsonl\"\n",
    "val_dir = \"../data/ADE20K-pairs/captions/ade20k_validation_captions.jsonl\"\n",
    "\n",
    "train_df = pd.read_json(train_dir,lines=True, orient=\"records\")[['image_id','caption']]\n",
    "train_df = train_df.drop_duplicates(subset=\"image_id\", keep=\"first\")\n",
    "val_df = pd.read_json(val_dir,lines=True, orient=\"records\")[['image_id','caption']]\n",
    "val_df = val_df.drop_duplicates(subset=\"image_id\", keep=\"first\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADE_val_00001410</td>\n",
       "      <td>In this picture I can see the vehicles on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADE_val_00001113</td>\n",
       "      <td>In this image I can see water and I can also s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADE_val_00000424</td>\n",
       "      <td>In this image we can see a table, light, book,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADE_val_00001210</td>\n",
       "      <td>This image is taken outdoors. At the top of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADE_val_00001480</td>\n",
       "      <td>In this image, there are cupboards, stove, mic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_id                                            caption\n",
       "0  ADE_val_00001410  In this picture I can see the vehicles on the ...\n",
       "1  ADE_val_00001113  In this image I can see water and I can also s...\n",
       "2  ADE_val_00000424  In this image we can see a table, light, book,...\n",
       "3  ADE_val_00001210  This image is taken outdoors. At the top of th...\n",
       "4  ADE_val_00001480  In this image, there are cupboards, stove, mic..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20210, 2), (2000, 2))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localized Narratives Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens:  983687\n",
      "Total unique tokens:  3247\n",
      "Avg. no. of tokens:  48.6732805541811\n",
      "Avg. no. of characters:  211.35106382978722\n"
     ]
    }
   ],
   "source": [
    "lines = train_df.caption.to_list()\n",
    "\n",
    "tokens = []\n",
    "tokens.extend([w.lower() for line in lines for w in wordpunct_tokenize(line)])\n",
    "print(\"Total tokens: \", len(tokens))\n",
    "print(\"Total unique tokens: \", len(set(tokens))) #Total unique tokens\n",
    "\n",
    "print(\"Avg. no. of tokens: \", \\\n",
    "      np.mean([len(wordpunct_tokenize(i)) for i in lines])) #Average number of tokens in the training set\n",
    "\n",
    "print(\"Avg. no. of characters: \",\\\n",
    "      np.mean([len(i) for i in lines])) #Average sequence length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/dataset-exploration/clip-finetune-ade20k/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20210, 2000)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dict()\n",
    "val = dict()\n",
    "\n",
    "basepath = \"../data/\"\n",
    "\n",
    "with jsonlines.open(basepath+'ade20k-train-combined.jsonl','r') as f:\n",
    "    for row in f:\n",
    "        train.update(row)        \n",
    "\n",
    "with jsonlines.open(basepath+'ade20k-val-combined.jsonl','r') as f:\n",
    "    for row in f:\n",
    "        val.update(row)        \n",
    "len(train.keys()), len(val.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['scene-type-coarse', 'scene-type-fine', 'caption', 'objects', 'qa-pairs', 'qa-binary'])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ADE_train_00003661'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene-type distribution - train:  Counter({'urban': 5801, 'home or hotel': 5219, 'unclassified': 2294, 'nature landscape': 1725, 'work place': 1189, 'sports and leisure': 1183, 'cultural': 1005, 'shopping and dining': 878, 'transportation': 653, 'industrial': 263})\n",
      "scene-type distribution - val:  Counter({'urban': 565, 'home or hotel': 534, 'unclassified': 223, 'nature landscape': 150, 'work place': 127, 'sports and leisure': 121, 'cultural': 102, 'shopping and dining': 89, 'transportation': 62, 'industrial': 27})\n"
     ]
    }
   ],
   "source": [
    "coarse_ = []\n",
    "\n",
    "for k, v in train.items():\n",
    "    coarse_.append(v['scene-type-coarse'])\n",
    "    \n",
    "print(\"scene-type distribution - train: \", collections.Counter(coarse_))\n",
    "\n",
    "coarse_ = []\n",
    "for k, v in val.items():\n",
    "    coarse_.append(v['scene-type-coarse'])\n",
    "    \n",
    "print(\"scene-type distribution - val: \", collections.Counter(coarse_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_embedding_pairs = np.load(\"../outputs/clip-embeddings/finetuned-img-embeddings-train.npy\", allow_pickle=True)\n",
    "train_img_embedding_pairs = train_img_embedding_pairs.item()\n",
    "\n",
    "val_img_embedding_pairs = np.load(\"../outputs/clip-embeddings/finetuned-img-embeddings-val.npy\", allow_pickle=True)\n",
    "val_img_embedding_pairs = val_img_embedding_pairs.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, embs = list(train_img_embedding_pairs.keys()), list(train_img_embedding_pairs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='white', context='poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_labels = []\n",
    "for i in ids:\n",
    "    coarse_labels.append(train[i]['scene-type-coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_neighbors=20, \n",
    "                  n_components=2, \n",
    "                  min_dist=0.05, \n",
    "                  metric='cosine',\n",
    "                  densmap=False,\n",
    "                  verbose=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(angular_rp_forest=True, dens_frac=0.0, dens_lambda=0.0, metric='cosine',\n",
      "     min_dist=0.05, n_neighbors=20, verbose=True)\n",
      "Construct fuzzy simplicial set\n",
      "Sun Sep  5 22:21:19 2021 Finding Nearest Neighbors\n",
      "Sun Sep  5 22:21:19 2021 Building RP forest with 12 trees\n",
      "Sun Sep  5 22:21:19 2021 NN descent for 14 iterations\n",
      "\t 1  /  14\n",
      "\t 2  /  14\n",
      "\t 3  /  14\n",
      "\t 4  /  14\n",
      "\tStopping threshold met -- exiting after 4 iterations\n",
      "Sun Sep  5 22:21:21 2021 Finished Nearest Neighbor Search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ragarwal/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning:\n",
      "\n",
      "Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep  5 22:21:22 2021 Construct embedding\n",
      "\tcompleted  0  /  200 epochs\n",
      "\tcompleted  20  /  200 epochs\n",
      "\tcompleted  40  /  200 epochs\n",
      "\tcompleted  60  /  200 epochs\n",
      "\tcompleted  80  /  200 epochs\n",
      "\tcompleted  100  /  200 epochs\n",
      "\tcompleted  120  /  200 epochs\n",
      "\tcompleted  140  /  200 epochs\n",
      "\tcompleted  160  /  200 epochs\n",
      "\tcompleted  180  /  200 epochs\n",
      "Sun Sep  5 22:21:35 2021 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "data = np.array(np.vstack([embs]), dtype=np.float64)\n",
    "target = np.hstack([coarse_labels])\n",
    "data.shape, target.shape\n",
    "\n",
    "embedding = umap_model.fit_transform(data, y=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe' # or 'notebook' or 'colab' or 'jupyterlab'\n",
    "\n",
    "classes = list(set(coarse_labels))\n",
    "colors = px.colors.qualitative.Bold\n",
    "color_discrete_map = dict(zip(classes, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_50.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(\n",
    "    embedding, x=0, y=1,\n",
    "    color=target, labels={'color': 'class'}, color_discrete_map=color_discrete_map\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"bottom\",\n",
    "    y=0.01,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01,\n",
    "    font=dict(size=12,),\n",
    "    itemsizing='trace'\n",
    "))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "#colors: https://plotly.com/python/discrete-color/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep  5 22:21:44 2021 Worst tree score: 0.58164275\n",
      "Sun Sep  5 22:21:44 2021 Mean tree score: 0.59373660\n",
      "Sun Sep  5 22:21:44 2021 Best tree score: 0.60400792\n",
      "Sun Sep  5 22:21:44 2021 Forward diversification reduced edges from 404200 to 140990\n",
      "Sun Sep  5 22:21:44 2021 Reverse diversification reduced edges from 140990 to 140990\n",
      "Sun Sep  5 22:21:44 2021 Degree pruning reduced edges from 167288 to 167250\n",
      "Sun Sep  5 22:21:44 2021 Resorting data and graph based on tree order\n",
      "Sun Sep  5 22:21:44 2021 Compressing index by removing unneeded attributes\n",
      "Sun Sep  5 22:21:44 2021 Building and compiling search function\n",
      "\tcompleted  0  /  100 epochs\n",
      "\tcompleted  10  /  100 epochs\n",
      "\tcompleted  20  /  100 epochs\n",
      "\tcompleted  30  /  100 epochs\n",
      "\tcompleted  40  /  100 epochs\n",
      "\tcompleted  50  /  100 epochs\n",
      "\tcompleted  60  /  100 epochs\n",
      "\tcompleted  70  /  100 epochs\n",
      "\tcompleted  80  /  100 epochs\n",
      "\tcompleted  90  /  100 epochs\n"
     ]
    }
   ],
   "source": [
    "val_ids, val_embs = list(val_img_embedding_pairs.keys()), list(val_img_embedding_pairs.values())\n",
    "val_embs = umap_model.transform(val_embs)\n",
    "coarse_labels_val = []\n",
    "for i in val_ids:\n",
    "    coarse_labels_val.append(val[i]['scene-type-coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_50.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig = px.scatter(\n",
    "    val_embs, x=0, y=1,\n",
    "    color=coarse_labels_val, labels={'color': 'class'}, color_discrete_map=color_discrete_map\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"bottom\",\n",
    "    y=0.01,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01,\n",
    "    font=dict(size=12,),\n",
    "    itemsizing='trace'\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_50.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "animals=['giraffes', 'orangutans', 'monkeys']\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='SF Zoo', x=animals, y=[20, 14, 23], text=[20, 14, 23], textposition='auto'),\n",
    "    go.Bar(name='LA Zoo', x=animals, y=[12, 18, 29], text=[12, 18, 29], textposition='auto')\n",
    "])\n",
    "\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
